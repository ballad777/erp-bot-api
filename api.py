import os
import re
import time
import uuid
import json
import logging
import glob
import requests
from typing import Dict, List, Any, Optional
from datetime import datetime

from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
from fastapi.responses import Response, JSONResponse
from sqlalchemy import create_engine, text, inspect
import pandas as pd
import httpx

# âŒ ç§»é™¤ Matplotlib (ä¸å†éœ€è¦ç¹ªåœ–)

from google import genai
from google.genai import types

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Smart ERP Bot", version="Text_Analysis_Only")

# =========================
# è³‡æ–™åº«é€£ç·š
# =========================
DATABASE_URL = os.getenv("DATABASE_URL")
if DATABASE_URL and DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)
if not DATABASE_URL:
    DATABASE_URL = "sqlite:///./erp.db"

engine = create_engine(DATABASE_URL, pool_pre_ping=True)

# =========================
# LINE & Gemini è¨­å®š
# =========================
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "")
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET", "")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")

# Google Drive Excel é€£çµ
SALES_EXCEL_URL = os.getenv("SALES_EXCEL_URL", "")
PURCHASE_EXCEL_URL = os.getenv("PURCHASE_EXCEL_URL", "")

if not LINE_CHANNEL_ACCESS_TOKEN:
    logger.warning("âš ï¸ LINE_CHANNEL_ACCESS_TOKEN æœªè¨­å®š")
if not GEMINI_API_KEY:
    logger.warning("âš ï¸ GEMINI_API_KEY æœªè¨­å®š")

client = None
if GEMINI_API_KEY:
    client = genai.Client(api_key=GEMINI_API_KEY)

# =========================
# è¨˜æ†¶é«”å­˜å„²
# =========================
CHAT_MEMORY: Dict[str, List[Any]] = {} 
# ç§»é™¤ IMG_STORE (ä¸å†éœ€è¦å­˜åœ–ç‰‡)

# =========================
# ğŸ“¥ Google Drive ä¸‹è¼‰èˆ‡è³‡æ–™åŒ¯å…¥é‚è¼¯
# =========================
def get_drive_id(url: str) -> str:
    """å¾ Google Drive é€£çµæå– File ID"""
    patterns = [
        r'/file/d/([a-zA-Z0-9_-]+)',
        r'id=([a-zA-Z0-9_-]+)',
        r'/spreadsheets/d/([a-zA-Z0-9_-]+)'
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return ""

def download_file_from_google_drive(id: str, destination: str):
    """ä¸‹è¼‰ Google Drive æª”æ¡ˆ"""
    URL = "https://docs.google.com/uc?export=download"
    session = requests.Session()
    
    logger.info(f"æ­£åœ¨ä¸‹è¼‰æª”æ¡ˆ ID: {id} åˆ° {destination}...")
    try:
        response = session.get(URL, params={'id': id}, stream=True)
        token = None
        for key, value in response.cookies.items():
            if key.startswith('download_warning'):
                token = value
                break
        
        if token:
            params = {'id': id, 'confirm': token}
            response = session.get(URL, params=params, stream=True)
            
        if response.status_code == 200:
            with open(destination, "wb") as f:
                for chunk in response.iter_content(32768):
                    if chunk:
                        f.write(chunk)
            logger.info(f"âœ… ä¸‹è¼‰æˆåŠŸ: {destination}")
            return True
        else:
            logger.error(f"âŒ ä¸‹è¼‰å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"âŒ ä¸‹è¼‰ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return False

def import_data_to_db():
    """ä¸‹è¼‰ä¸¦åŒ¯å…¥è³‡æ–™åˆ°è³‡æ–™åº«"""
    logger.info("ğŸ”„ é–‹å§‹åŸ·è¡Œè³‡æ–™åˆå§‹åŒ–ç¨‹åº...")
    
    sales_file = "sales_data.xlsx"
    purchase_file = "purchase_data.xlsx"
    has_sales = False
    has_purchase = False
    
    # ä¸‹è¼‰ Sales
    if SALES_EXCEL_URL:
        if download_file_from_google_drive(get_drive_id(SALES_EXCEL_URL), sales_file):
            has_sales = True
    elif os.path.exists(sales_file): has_sales = True

    # ä¸‹è¼‰ Purchase
    if PURCHASE_EXCEL_URL:
        if download_file_from_google_drive(get_drive_id(PURCHASE_EXCEL_URL), purchase_file):
            has_purchase = True
    elif os.path.exists(purchase_file): has_purchase = True
            
    try:
        # è™•ç† Sales
        if has_sales:
            logger.info(f"æ­£åœ¨è®€å–éŠ·å”® Excel: {sales_file}")
            xls = pd.read_excel(sales_file, sheet_name=None)
            all_sales = []
            for sheet_name, df in xls.items():
                df.columns = df.columns.str.strip() # å»é™¤æ¬„ä½ç©ºç™½
                # æª¢æŸ¥é—œéµæ¬„ä½
                if 'æ—¥æœŸ(è½‰æ›)' in df.columns and 'é€²éŠ·æ˜ç´°æœªç¨…é‡‘é¡' in df.columns:
                    clean_df = pd.DataFrame({
                        'date': pd.to_datetime(df['æ—¥æœŸ(è½‰æ›)'], errors='coerce'),
                        'customer': df['å®¢æˆ¶ä¾›æ‡‰å•†ç°¡ç¨±'],
                        'product': df['å“å'],
                        'quantity': pd.to_numeric(df['æ•¸é‡'], errors='coerce').fillna(0),
                        'amount': pd.to_numeric(df['é€²éŠ·æ˜ç´°æœªç¨…é‡‘é¡'], errors='coerce').fillna(0)
                    })
                    clean_df = clean_df.dropna(subset=['date'])
                    clean_df['year'] = clean_df['date'].dt.year
                    clean_df['date'] = clean_df['date'].dt.strftime('%Y-%m-%d')
                    all_sales.append(clean_df)
            
            if all_sales:
                final_sales = pd.concat(all_sales, ignore_index=True)
                final_sales.to_sql('sales', engine, if_exists='replace', index=False)
                logger.info(f"âœ… Sales è³‡æ–™åŒ¯å…¥å®Œæˆï¼Œå…± {len(final_sales)} ç­†")

        # è™•ç† Purchase
        if has_purchase:
            logger.info(f"æ­£åœ¨è®€å–æ¡è³¼ Excel: {purchase_file}")
            xls = pd.read_excel(purchase_file, sheet_name=None)
            all_purchase = []
            for sheet_name, df in xls.items():
                df.columns = df.columns.str.strip()
                if 'æ—¥æœŸ(è½‰æ›)' in df.columns and 'é€²éŠ·æ˜ç´°æœªç¨…é‡‘é¡' in df.columns:
                    prod_col = 'å°æ–¹å“å/å“åå‚™è¨»' if 'å°æ–¹å“å/å“åå‚™è¨»' in df.columns else 'å“å'
                    clean_df = pd.DataFrame({
                        'date': pd.to_datetime(df['æ—¥æœŸ(è½‰æ›)'], errors='coerce'),
                        'supplier': df['å®¢æˆ¶ä¾›æ‡‰å•†ç°¡ç¨±'],
                        'product': df[prod_col],
                        'quantity': pd.to_numeric(df['æ•¸é‡'], errors='coerce').fillna(0),
                        'amount': pd.to_numeric(df['é€²éŠ·æ˜ç´°æœªç¨…é‡‘é¡'], errors='coerce').fillna(0)
                    })
                    clean_df = clean_df.dropna(subset=['date'])
                    clean_df['year'] = clean_df['date'].dt.year
                    clean_df['date'] = clean_df['date'].dt.strftime('%Y-%m-%d')
                    all_purchase.append(clean_df)
            
            if all_purchase:
                final_purchase = pd.concat(all_purchase, ignore_index=True)
                final_purchase.to_sql('purchase', engine, if_exists='replace', index=False)
                logger.info(f"âœ… Purchase è³‡æ–™åŒ¯å…¥å®Œæˆï¼Œå…± {len(final_purchase)} ç­†")

    except Exception as e:
        logger.error(f"âŒ è³‡æ–™åŒ¯å…¥åš´é‡éŒ¯èª¤: {str(e)}")

# =========================
# å·¥å…·å‡½æ•¸
# =========================
def execute_sql_query(sql: str) -> str:
    """ã€å·¥å…·ã€‘åŸ·è¡Œ SQL SELECT æŸ¥è©¢ sales æˆ– purchase è¡¨ã€‚"""
    logger.info(f"åŸ·è¡Œ SQL: {sql}")
    sql = sql.replace("```sql", "").replace("```", "").strip()
    
    if not sql.lower().startswith("select"): return "éŒ¯èª¤ï¼šåªå…è¨± SELECT æŸ¥è©¢ã€‚"
    if any(k in sql.lower() for k in ['drop', 'delete', 'update', 'insert', 'alter']):
        return "éŒ¯èª¤ï¼šç¦æ­¢ä¿®æ”¹è³‡æ–™åº«ã€‚"
    
    try:
        insp = inspect(engine)
        table_names = insp.get_table_names()
        
        if 'sales' in sql.lower() and 'sales' not in table_names:
            return "ç³»çµ±éŒ¯èª¤ï¼šéŠ·å”®è³‡æ–™è¡¨ (sales) å°šæœªå»ºç«‹ï¼Œè«‹ç¢ºèªè³‡æ–™æ˜¯å¦å·²åŒ¯å…¥ã€‚"
        if 'purchase' in sql.lower() and 'purchase' not in table_names:
            return "ç³»çµ±éŒ¯èª¤ï¼šæ¡è³¼è³‡æ–™è¡¨ (purchase) å°šæœªå»ºç«‹ã€‚"

        with engine.connect() as conn:
            df = pd.read_sql(text(sql), conn)
            if df.empty: return "æŸ¥ç„¡è³‡æ–™ã€‚"
            
            for col in df.select_dtypes(include=['datetime64']).columns:
                df[col] = df[col].astype(str)
            
            # é™åˆ¶å›å‚³ç­†æ•¸ï¼Œé¿å… JSON éå¤§
            if len(df) > 50:
                logger.info(f"çµæœéå¤š ({len(df)})ï¼Œåƒ…å›å‚³å‰ 50 ç­†")
                df = df.head(50)
                
            return df.to_json(orient="records", force_ascii=False, date_format='iso')
    except Exception as e:
        return f"SQL Error: {str(e)}"

def get_database_schema() -> str:
    """ã€å·¥å…·ã€‘å–å¾—è³‡æ–™è¡¨çµæ§‹"""
    try:
        insp = inspect(engine)
        table_names = insp.get_table_names()
        summary = {}
        with engine.connect() as conn:
            for t_name in table_names:
                if t_name not in ['sales', 'purchase']: continue
                cols = conn.execute(text(f"SELECT * FROM {t_name} LIMIT 1")).keys()
                count = conn.execute(text(f"SELECT COUNT(*) FROM {t_name}")).scalar()
                summary[t_name] = {'columns': list(cols), 'count': count}
        return json.dumps(summary, ensure_ascii=False)
    except Exception as e:
        return f"Error: {str(e)}"

# âŒ ç§»é™¤ create_chart å·¥å…·
tools_list = [execute_sql_query, get_database_schema]

# =========================
# ç³»çµ±æç¤ºè© (æ¥µç°¡é¢¨æ ¼èª¿æ•™)
# =========================
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­ã€ä¿è½çš„ ERP å•†æ¥­åˆ†æå¸«ã€‚
è«‹æ ¹æ“šè³‡æ–™åº«ä¸­çš„ `sales` (éŠ·å”®) èˆ‡ `purchase` (æ¡è³¼) è³‡æ–™è¡¨å›ç­”å•é¡Œã€‚

## âš ï¸ å›ç­”é¢¨æ ¼è¦ç¯„ (Violations will be punished)
1. **åš´ç¦ä½¿ç”¨ Markdown æ ¼å¼**ï¼š
   - çµ•å°ä¸è¦ä½¿ç”¨ç±³å­—è™Ÿ `*` æˆ– `**`ã€‚
   - çµ•å°ä¸è¦ä½¿ç”¨äº•å­—è™Ÿ `#` åšæ¨™é¡Œã€‚
   - è«‹ä½¿ç”¨ç´”æ–‡å­—ï¼Œç”¨æ›è¡Œæˆ–é€£å­—è™Ÿ `-` ä¾†æ¢åˆ—é‡é»ã€‚
   
2. **å°ˆæ³¨æ–‡å­—åˆ†æ**ï¼š
   - ç”¨æˆ¶**ä¸éœ€è¦åœ–è¡¨**ã€‚
   - è«‹æ¶ˆåŒ–æ•¸æ“šå¾Œï¼Œç”¨æ–‡å­—æä¾›ã€Œæ´å¯Ÿ (Insights)ã€ã€‚
   - ä¾‹å¦‚ï¼šä¸è¦åªåˆ—å‡ºæ•¸å­—ï¼Œè¦å‘Šè¨´ç”¨æˆ¶ã€Œè·Ÿå»å¹´æ¯”æˆé•·äº†å¤šå°‘ã€æˆ–ã€Œå“ªå€‹å®¢æˆ¶ä½”æ¯”æœ€é«˜ã€ã€‚

3. **å›ç­”ç²¾ç°¡æ‰¼è¦**ï¼š
   - é™¤éç”¨æˆ¶è¦æ±‚ã€Œè©³ç´°æ¸…å–®ã€ï¼Œå¦å‰‡é è¨­åªçµ¦ç¸½çµæ•¸æ“šã€‚
   - ä¸è¦æŠŠ JSON è³‡æ–™ç›´æ¥è²¼å‡ºä¾†ã€‚

4. **å°ˆæ³¨ç•¶ä¸‹**ï¼š
   - åªå›ç­”ç”¨æˆ¶æœ€æ–°ä¸€æ¬¡è¼¸å…¥çš„å•é¡Œï¼Œå¿½ç•¥ç„¡é—œçš„æ­·å²å°è©±ã€‚

5. **æ¨¡ç³Šæœå°‹**ï¼š
   - ç”¨æˆ¶æ‰“éŒ¯å­—æˆ–æ‰“ç°¡ç¨±ï¼ˆå¦‚ "ipone", "è¯ç¢©"ï¼‰ï¼Œè«‹è‡ªå‹•ç”¨ `LIKE` ä¿®æ­£æŸ¥è©¢ã€‚

## è³‡æ–™è¡¨çµæ§‹
- `sales` (éŠ·å”®): date, customer, product, quantity, amount, year
- `purchase` (æ¡è³¼): date, supplier, product, quantity, amount, year
"""

# =========================
# Agent è™•ç†é‚è¼¯
# =========================
async def agent_process(user_id: str, text: str, base_url: str):
    if not client: return {"text": "API Key æœªè¨­å®š"}
    
    # åªå–æœ€è¿‘ 2 è¼ªå°è©±ï¼Œä¿æŒå°è©±ä¹¾æ·¨
    history = CHAT_MEMORY.get(user_id, [])[-2:] 
    
    user_message = types.Content(role="user", parts=[types.Part(text=text)])
    contents = history + [user_message]
    
    config = types.GenerateContentConfig(
        tools=tools_list,
        system_instruction=SYSTEM_PROMPT,
        temperature=0.2 # ä½æº«ï¼Œè®“å›ç­”æ›´æ”¶æ–‚
    )
    
    final_text = "æŠ±æ­‰ï¼Œç„¡æ³•è™•ç†ã€‚"
    
    try:
        response = client.models.generate_content(
            model="gemini-flash-latest",
            contents=contents,
            config=config
        )
        
        if response.candidates:
            candidate = response.candidates[0]
            for _ in range(5): 
                has_tool = False
                for part in candidate.content.parts:
                    if part.function_call:
                        has_tool = True
                        fc = part.function_call
                        logger.info(f"Tool Call: {fc.name}")
                        
                        res = ""
                        if fc.name == "execute_sql_query":
                            res = execute_sql_query(fc.args.get("sql", ""))
                        elif fc.name == "get_database_schema":
                            res = get_database_schema()
                        
                        contents.append(candidate.content)
                        contents.append(types.Content(
                            role="user",
                            parts=[types.Part(
                                function_response=types.FunctionResponse(
                                    name=fc.name,
                                    response={"result": res}
                                )
                            )]
                        ))
                        
                        response = client.models.generate_content(
                            model="gemini-flash-latest",
                            contents=contents,
                            config=config
                        )
                        candidate = response.candidates[0]
                        break 
                
                if not has_tool:
                    final_text = response.text
                    break

        # æ›´æ–°è¨˜æ†¶
        CHAT_MEMORY[user_id] = contents[-4:]
        
        # å†æ¬¡éæ¿¾ç±³å­—è™Ÿ (é›™é‡ä¿éšª)
        final_text = final_text.replace("*", "").replace("#", "")
        
        return {"text": final_text, "image": None}
        
    except Exception as e:
        logger.error(f"Agent Error: {e}")
        return {"text": f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}"}

# =========================
# API ç«¯é»
# =========================
@app.get("/")
def root():
    return {"status": "ok", "service": "ERP Bot (Text Only)"}

@app.get("/health")
def health_check():
    return {"status": "ok"}

@app.post("/line/webhook")
async def webhook(request: Request, background_tasks: BackgroundTasks):
    body = await request.body()
    signature = request.headers.get("X-Line-Signature", "")
    
    if LINE_CHANNEL_SECRET:
        import hmac, hashlib, base64
        hash_val = hmac.new(LINE_CHANNEL_SECRET.encode('utf-8'), body, hashlib.sha256).digest()
        expected = base64.b64encode(hash_val).decode('utf-8')
        if signature != expected: raise HTTPException(400, "Invalid Signature")

    try:
        events = json.loads(body.decode("utf-8")).get("events", [])
    except: return {"ok": False}
    
    base_url = f"https://{request.headers.get('host', 'localhost')}"
    
    for event in events:
        if event.get("type") == "message" and event.get("message", {}).get("type") == "text":
            user_id = event["source"]["userId"]
            text = event["message"]["text"]
            reply_token = event["replyToken"]
            background_tasks.add_task(handle_message, user_id, text, reply_token, base_url)
            
    return {"ok": True}

async def handle_message(user_id: str, text: str, reply_token: str, base_url: str):
    try:
        if text.lower() in ['/reset', 'æ¸…é™¤']:
            CHAT_MEMORY.pop(user_id, None)
            await reply_line(reply_token, "è¨˜æ†¶å·²æ¸…é™¤", None)
            return

        result = await agent_process(user_id, text, base_url)
        await reply_line(reply_token, result.get("text"), None)
    except Exception as e:
        logger.error(f"Handle Error: {e}")
        await reply_line(reply_token, "ç³»çµ±å¿™ç¢Œä¸­", None)

async def reply_line(token: str, text: Optional[str], img_url: Optional[str]):
    if not LINE_CHANNEL_ACCESS_TOKEN: return
    headers = {"Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}", "Content-Type": "application/json"}
    messages = []
    # é€™è£¡å·²ç¶“ä¸éœ€è¦ img_url äº†ï¼Œä½†ç‚ºäº†ç›¸å®¹æ€§ä¿ç•™åƒæ•¸
    if text: messages.append({"type": "text", "text": text[:4999]})
    if not messages: messages.append({"type": "text", "text": "..."})
    
    async with httpx.AsyncClient() as c:
        await c.post("https://api.line.me/v2/bot/message/reply", headers=headers, json={"replyToken": token, "messages": messages})

@app.on_event("startup")
async def startup():
    """å•Ÿå‹•æ™‚è‡ªå‹•ä¸‹è¼‰ä¸¦åŒ¯å…¥è³‡æ–™"""
    try:
        import_data_to_db()
    except Exception as e:
        logger.error(f"Startup Error: {e}")
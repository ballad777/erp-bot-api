import os
import re
import time
import uuid
import json
import logging
import glob
import requests
from typing import Dict, List, Any, Optional
from datetime import datetime

from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
from fastapi.responses import Response, JSONResponse
from sqlalchemy import create_engine, text
import pandas as pd
import httpx

import matplotlib
# è¨­å®š Matplotlib å¾Œç«¯ç‚º Agg (é˜²æ­¢ä¼ºæœå™¨ç¹ªåœ–éŒ¯èª¤)
matplotlib.use("Agg") 
import matplotlib.pyplot as plt
from io import BytesIO

from google import genai
from google.genai import types

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Smart ERP Bot", version="Final_Drive_Integrated")

# =========================
# è³‡æ–™åº«é€£ç·š
# =========================
DATABASE_URL = os.getenv("DATABASE_URL")
if DATABASE_URL and DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)
if not DATABASE_URL:
    DATABASE_URL = "sqlite:///./erp.db"

engine = create_engine(DATABASE_URL, pool_pre_ping=True)

# =========================
# LINE & Gemini è¨­å®š
# =========================
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "")
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET", "")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")

# Google Drive Excel é€£çµ (å¾ç’°å¢ƒè®Šæ•¸è®€å–)
SALES_EXCEL_URL = os.getenv("SALES_EXCEL_URL", "")
PURCHASE_EXCEL_URL = os.getenv("PURCHASE_EXCEL_URL", "")

if not LINE_CHANNEL_ACCESS_TOKEN:
    logger.warning("âš ï¸ LINE_CHANNEL_ACCESS_TOKEN æœªè¨­å®š")
if not GEMINI_API_KEY:
    logger.warning("âš ï¸ GEMINI_API_KEY æœªè¨­å®š")

client = None
if GEMINI_API_KEY:
    client = genai.Client(api_key=GEMINI_API_KEY)

# =========================
# è¨˜æ†¶é«”å­˜å„²
# =========================
CHAT_MEMORY: Dict[str, List[Any]] = {} 
IMG_STORE: Dict[str, Dict[str, Any]] = {}

# =========================
# ğŸ“¥ Google Drive ä¸‹è¼‰èˆ‡è³‡æ–™åŒ¯å…¥é‚è¼¯
# =========================
def get_drive_id(url: str) -> str:
    """å¾ Google Drive é€£çµæå– File ID"""
    patterns = [
        r'/file/d/([a-zA-Z0-9_-]+)',
        r'id=([a-zA-Z0-9_-]+)',
        r'/spreadsheets/d/([a-zA-Z0-9_-]+)'
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return ""

def download_file_from_google_drive(id: str, destination: str):
    """ä¸‹è¼‰ Google Drive æª”æ¡ˆ (æ”¯æ´å¤§æª”æ¡ˆç¢ºèª)"""
    URL = "https://docs.google.com/uc?export=download"
    session = requests.Session()
    
    logger.info(f"æ­£åœ¨ä¸‹è¼‰æª”æ¡ˆ ID: {id} åˆ° {destination}...")
    try:
        response = session.get(URL, params={'id': id}, stream=True)
        token = None
        for key, value in response.cookies.items():
            if key.startswith('download_warning'):
                token = value
                break
        
        if token:
            params = {'id': id, 'confirm': token}
            response = session.get(URL, params=params, stream=True)
            
        if response.status_code == 200:
            with open(destination, "wb") as f:
                for chunk in response.iter_content(32768):
                    if chunk:
                        f.write(chunk)
            logger.info(f"âœ… ä¸‹è¼‰æˆåŠŸ: {destination}")
            return True
        else:
            logger.error(f"âŒ ä¸‹è¼‰å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"âŒ ä¸‹è¼‰ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return False

def import_data_to_db():
    """ä¸‹è¼‰ä¸¦åŒ¯å…¥è³‡æ–™åˆ°è³‡æ–™åº«"""
    logger.info("ğŸ”„ é–‹å§‹åŸ·è¡Œè³‡æ–™åˆå§‹åŒ–ç¨‹åº...")
    
    # 1. ä¸‹è¼‰æª”æ¡ˆ
    sales_file = "sales_data.xlsx"
    purchase_file = "purchase_data.xlsx"
    
    has_sales = False
    has_purchase = False
    
    # è™•ç†éŠ·å”®æª”æ¡ˆ
    if SALES_EXCEL_URL:
        file_id = get_drive_id(SALES_EXCEL_URL)
        if file_id and download_file_from_google_drive(file_id, sales_file):
            has_sales = True
    else:
        # å¦‚æœæ²’è¨­å®š URLï¼Œæª¢æŸ¥æ˜¯å¦æœ‰æœ¬åœ°æª”æ¡ˆ
        if os.path.exists(sales_file): has_sales = True
        elif glob.glob("sales*.xlsx"): 
            sales_file = glob.glob("sales*.xlsx")[0]
            has_sales = True

    # è™•ç†æ¡è³¼æª”æ¡ˆ
    if PURCHASE_EXCEL_URL:
        file_id = get_drive_id(PURCHASE_EXCEL_URL)
        if file_id and download_file_from_google_drive(file_id, purchase_file):
            has_purchase = True
    else:
        if os.path.exists(purchase_file): has_purchase = True
        elif glob.glob("purchase*.xlsx"): 
            purchase_file = glob.glob("purchase*.xlsx")[0]
            has_purchase = True
            
    # 2. è®€å–ä¸¦åŒ¯å…¥è³‡æ–™åº«
    try:
        # --- åŒ¯å…¥ Sales ---
        if has_sales:
            logger.info(f"æ­£åœ¨è®€å–éŠ·å”® Excel: {sales_file}")
            # è®€å–æ‰€æœ‰ sheet
            xls = pd.read_excel(sales_file, sheet_name=None)
            all_sales = []
            
            for sheet_name, df in xls.items():
                logger.info(f"  - è™•ç†åˆ†é : {sheet_name}")
                # æª¢æŸ¥å¿…è¦æ¬„ä½ (æ ¹æ“šæ‚¨æä¾›çš„ CSV æ¬„ä½åç¨±)
                # æ¬„ä½: æ—¥æœŸ(è½‰æ›), å®¢æˆ¶ä¾›æ‡‰å•†ç°¡ç¨±, å“å, æ•¸é‡, é€²éŠ·æ˜ç´°æœªç¨…é‡‘é¡
                if 'æ—¥æœŸ(è½‰æ›)' in df.columns and 'é€²éŠ·æ˜ç´°æœªç¨…é‡‘é¡' in df.columns:
                    clean_df = pd.DataFrame({
                        'date': pd.to_datetime(df['æ—¥æœŸ(è½‰æ›)'], errors='coerce'),
                        'customer': df['å®¢æˆ¶ä¾›æ‡‰å•†ç°¡ç¨±'],
                        'product': df['å“å'], # éŠ·å”®æª”é€šå¸¸å« 'å“å'
                        'quantity': pd.to_numeric(df['æ•¸é‡'], errors='coerce').fillna(0),
                        'amount': pd.to_numeric(df['é€²éŠ·æ˜ç´°æœªç¨…é‡‘é¡'], errors='coerce').fillna(0)
                    })
                    # ç§»é™¤æ—¥æœŸç„¡æ•ˆçš„è³‡æ–™
                    clean_df = clean_df.dropna(subset=['date'])
                    clean_df['year'] = clean_df['date'].dt.year
                    clean_df['date'] = clean_df['date'].dt.strftime('%Y-%m-%d')
                    all_sales.append(clean_df)
            
            if all_sales:
                final_sales = pd.concat(all_sales, ignore_index=True)
                final_sales.to_sql('sales', engine, if_exists='replace', index=False)
                logger.info(f"âœ… Sales è³‡æ–™åŒ¯å…¥å®Œæˆï¼Œå…± {len(final_sales)} ç­†")
            else:
                logger.warning("âš ï¸ Sales Excel ä¸­æ‰¾ä¸åˆ°ç¬¦åˆæ ¼å¼çš„åˆ†é ")
        else:
            logger.warning("âš ï¸ ç„¡æ³•æ‰¾åˆ°æˆ–ä¸‹è¼‰ Sales æª”æ¡ˆ")

        # --- åŒ¯å…¥ Purchase ---
        if has_purchase:
            logger.info(f"æ­£åœ¨è®€å–æ¡è³¼ Excel: {purchase_file}")
            xls = pd.read_excel(purchase_file, sheet_name=None)
            all_purchase = []
            
            for sheet_name, df in xls.items():
                logger.info(f"  - è™•ç†åˆ†é : {sheet_name}")
                # æ¬„ä½: æ—¥æœŸ(è½‰æ›), å®¢æˆ¶ä¾›æ‡‰å•†ç°¡ç¨±, å°æ–¹å“å/å“åå‚™è¨», æ•¸é‡, é€²éŠ·æ˜ç´°æœªç¨…é‡‘é¡
                if 'æ—¥æœŸ(è½‰æ›)' in df.columns and 'é€²éŠ·æ˜ç´°æœªç¨…é‡‘é¡' in df.columns:
                    # æ¡è³¼æª”çš„å“åæ¬„ä½å¯èƒ½ä¸åŒï¼Œå˜—è©¦æ‰¾ 'å°æ–¹å“å/å“åå‚™è¨»'
                    prod_col = 'å°æ–¹å“å/å“åå‚™è¨»' if 'å°æ–¹å“å/å“åå‚™è¨»' in df.columns else 'å“å'
                    
                    clean_df = pd.DataFrame({
                        'date': pd.to_datetime(df['æ—¥æœŸ(è½‰æ›)'], errors='coerce'),
                        'supplier': df['å®¢æˆ¶ä¾›æ‡‰å•†ç°¡ç¨±'],
                        'product': df[prod_col],
                        'quantity': pd.to_numeric(df['æ•¸é‡'], errors='coerce').fillna(0),
                        'amount': pd.to_numeric(df['é€²éŠ·æ˜ç´°æœªç¨…é‡‘é¡'], errors='coerce').fillna(0)
                    })
                    clean_df = clean_df.dropna(subset=['date'])
                    clean_df['year'] = clean_df['date'].dt.year
                    clean_df['date'] = clean_df['date'].dt.strftime('%Y-%m-%d')
                    all_purchase.append(clean_df)
            
            if all_purchase:
                final_purchase = pd.concat(all_purchase, ignore_index=True)
                final_purchase.to_sql('purchase', engine, if_exists='replace', index=False)
                logger.info(f"âœ… Purchase è³‡æ–™åŒ¯å…¥å®Œæˆï¼Œå…± {len(final_purchase)} ç­†")
            else:
                logger.warning("âš ï¸ Purchase Excel ä¸­æ‰¾ä¸åˆ°ç¬¦åˆæ ¼å¼çš„åˆ†é ")
        else:
            logger.warning("âš ï¸ ç„¡æ³•æ‰¾åˆ°æˆ–ä¸‹è¼‰ Purchase æª”æ¡ˆ")

    except Exception as e:
        logger.error(f"âŒ è³‡æ–™åŒ¯å…¥åš´é‡éŒ¯èª¤: {str(e)}")

# =========================
# å·¥å…·å‡½æ•¸
# =========================
def execute_sql_query(sql: str) -> str:
    """ã€å·¥å…·ã€‘åŸ·è¡Œ SQL SELECT æŸ¥è©¢ sales æˆ– purchase è¡¨ã€‚"""
    logger.info(f"åŸ·è¡Œ SQL: {sql}")
    
    # æ¸…æ´— SQL
    sql = sql.replace("```sql", "").replace("```", "").strip()
    sql_lower = sql.lower()
    if not sql_lower.startswith("select"):
        return "éŒ¯èª¤ï¼šåªå…è¨± SELECT æŸ¥è©¢ã€‚"
    
    # æª¢æŸ¥æ˜¯å¦å˜—è©¦ä¿®æ”¹è³‡æ–™
    if any(k in sql_lower for k in ['drop', 'delete', 'update', 'insert', 'alter']):
        return "éŒ¯èª¤ï¼šç¦æ­¢ä¿®æ”¹è³‡æ–™åº«ã€‚"
    
    try:
        with engine.connect() as conn:
            # æª¢æŸ¥ Table æ˜¯å¦å­˜åœ¨ (é˜²æ­¢ 'no such table' éŒ¯èª¤)
            tables = conn.execute(text("SELECT name FROM sqlite_master WHERE type='table'")).fetchall()
            table_names = [t[0] for t in tables]
            
            # å¦‚æœ SQL è£¡æåˆ°çš„è¡¨ä¸å­˜åœ¨ï¼Œå›å‚³å‹å–„éŒ¯èª¤
            if 'sales' in sql_lower and 'sales' not in table_names:
                return "ç³»çµ±éŒ¯èª¤ï¼šéŠ·å”®è³‡æ–™è¡¨ (sales) å°šæœªå»ºç«‹ï¼Œè«‹è¯ç¹«ç®¡ç†å“¡æª¢æŸ¥è³‡æ–™åŒ¯å…¥ç‹€æ³ã€‚"
            if 'purchase' in sql_lower and 'purchase' not in table_names:
                return "ç³»çµ±éŒ¯èª¤ï¼šæ¡è³¼è³‡æ–™è¡¨ (purchase) å°šæœªå»ºç«‹ã€‚"

            df = pd.read_sql(text(sql), conn)
            
            if df.empty: 
                return "æŸ¥è©¢æˆåŠŸä½†æ²’æœ‰æ‰¾åˆ°è³‡æ–™ã€‚è«‹å˜—è©¦æ”¾å¯¬æ¢ä»¶æˆ–ç¢ºèªé—œéµå­—ã€‚"
            
            # è½‰å­—ä¸²é¿å… JSON éŒ¯èª¤
            for col in df.select_dtypes(include=['datetime64']).columns:
                df[col] = df[col].astype(str)
            
            if len(df) > 100:
                logger.info(f"çµæœéå¤š ({len(df)})ï¼Œåƒ…å›å‚³å‰ 100 ç­†")
                df = df.head(100)
                
            return df.to_json(orient="records", force_ascii=False, date_format='iso')
    except Exception as e:
        logger.error(f"SQL åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
        return f"SQL Error: {str(e)}"

def create_chart(title: str, chart_type: str, data_json: str, x_key: str, y_key: str) -> str:
    """ã€å·¥å…·ã€‘ç¹ªè£½åœ–è¡¨ (bar/line/pie)ã€‚"""
    logger.info(f"ç¹ªè£½åœ–è¡¨: {title}")
    try:
        data = json.loads(data_json)
        df = pd.DataFrame(data)
        if df.empty: return "ç„¡è³‡æ–™ç¹ªåœ–"
        
        if x_key not in df.columns or y_key not in df.columns:
            return f"æ¬„ä½éŒ¯èª¤: {x_key} æˆ– {y_key} ä¸å­˜åœ¨"
        
        df[y_key] = pd.to_numeric(df[y_key], errors='coerce').fillna(0)
        
        plt.figure(figsize=(10, 6))
        plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False
        
        if chart_type == "line": plt.plot(df[x_key], df[y_key], marker='o')
        elif chart_type == "bar": plt.bar(df[x_key], df[y_key], color='steelblue')
        elif chart_type == "pie":
            df_s = df.sort_values(by=y_key, ascending=False).head(8)
            plt.pie(df_s[y_key], labels=df_s[x_key], autopct='%1.1f%%')
            
        plt.title(title, fontsize=14)
        plt.tight_layout()
        
        buf = BytesIO()
        plt.savefig(buf, format="png", dpi=100)
        plt.close()
        
        img_id = str(uuid.uuid4())
        IMG_STORE[img_id] = {"bytes": buf.getvalue(), "ts": time.time()}
        return f"IMAGE_ID:{img_id}"
    except Exception as e:
        return f"Chart Error: {str(e)}"

def get_database_schema() -> str:
    """ã€å·¥å…·ã€‘å–å¾—è³‡æ–™è¡¨çµæ§‹"""
    try:
        with engine.connect() as conn:
            tables = conn.execute(text("SELECT name FROM sqlite_master WHERE type='table'")).fetchall()
            summary = {}
            for t in tables:
                t_name = t[0]
                cols = conn.execute(text(f"SELECT * FROM {t_name} LIMIT 1")).keys()
                count = conn.execute(text(f"SELECT COUNT(*) FROM {t_name}")).scalar()
                summary[t_name] = {'columns': list(cols), 'count': count}
            return json.dumps(summary, ensure_ascii=False)
    except Exception as e:
        return f"Error: {str(e)}"

# =========================
# å·¥å…·åˆ—è¡¨
# =========================
tools_list = [execute_sql_query, create_chart, get_database_schema]

# =========================
# ç³»çµ±æç¤ºè©
# =========================
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ ERP æ•¸æ“šåŠ©ç†ã€‚
è«‹æ ¹æ“šè³‡æ–™åº«ä¸­çš„ `sales` (éŠ·å”®) èˆ‡ `purchase` (æ¡è³¼) è³‡æ–™è¡¨å›ç­”å•é¡Œã€‚

## é‡è¦æŒ‡ä»¤
1. **ç›´æ¥å›ç­”**ï¼šä¸è¦è‡ªæˆ‘ä»‹ç´¹ï¼Œä¸è¦èªªã€Œæˆ‘æ˜¯å°æ™ºã€ï¼Œç›´æ¥é‡å°å•é¡Œæä¾›æ•¸æ“šæˆ–åœ–è¡¨ã€‚
2. **æ¨¡ç³Šæœå°‹**ï¼šç”¨æˆ¶è¼¸å…¥çš„é—œéµå­—å¯èƒ½æœƒæœ‰éŒ¯å­—ï¼Œè«‹ä½¿ç”¨ `LIKE` é€²è¡Œæ¨¡ç³Šæ¯”å°ã€‚
   - ä¾‹å¦‚ï¼šç”¨æˆ¶æŸ¥ "ipone" -> SQL ç”¨ `product LIKE '%iPhone%'`
   - ä¾‹å¦‚ï¼šç”¨æˆ¶æŸ¥ "è¯ç¢©" -> SQL ç”¨ `customer LIKE '%è¯ç¢©%'`
3. **è³‡æ–™è¡¨çµæ§‹**ï¼š
   - sales: date, customer, product, quantity, amount, year
   - purchase: date, supplier, product, quantity, amount, year

## SQL è¦å‰‡
- æŸ¥è©¢ç¸½é¡ä½¿ç”¨ `SUM(amount)`
- æŸ¥è©¢éŠ·é‡ä½¿ç”¨ `SUM(quantity)`
- è‹¥æŸ¥ç„¡è³‡æ–™ï¼Œè«‹å˜—è©¦æ”¾å¯¬æ¢ä»¶ (ä¾‹å¦‚ç§»é™¤å¹´ä»½é™åˆ¶æˆ–ç°¡åŒ–é—œéµå­—)
"""

# =========================
# Agent è™•ç†é‚è¼¯
# =========================
async def agent_process(user_id: str, text: str, base_url: str):
    if not client: return {"text": "API Key æœªè¨­å®š"}
    
    history = CHAT_MEMORY.get(user_id, [])
    user_message = types.Content(role="user", parts=[types.Part(text=text)])
    contents = history + [user_message]
    
    config = types.GenerateContentConfig(
        tools=tools_list,
        system_instruction=SYSTEM_PROMPT,
        temperature=0.3
    )
    
    final_text = "æŠ±æ­‰ï¼Œç„¡æ³•è™•ç†ã€‚"
    image_url = None
    
    try:
        # ä½¿ç”¨ gemini-flash-latest (å°æ‡‰ 1.5 Flash)
        response = client.models.generate_content(
            model="gemini-flash-latest",
            contents=contents,
            config=config
        )
        
        # è™•ç† Function Call
        if response.candidates:
            candidate = response.candidates[0]
            # è¿´åœˆè™•ç†å·¥å…·å‘¼å« (æ”¯æ´å¤šè¼ª)
            for _ in range(5): # æœ€å¤š 5 è¼ª
                has_tool = False
                for part in candidate.content.parts:
                    if part.function_call:
                        has_tool = True
                        fc = part.function_call
                        logger.info(f"Tool Call: {fc.name}")
                        
                        res = ""
                        if fc.name == "execute_sql_query":
                            res = execute_sql_query(fc.args.get("sql", ""))
                        elif fc.name == "create_chart":
                            chart_res = create_chart(
                                fc.args.get("title", ""),
                                fc.args.get("chart_type", "bar"),
                                fc.args.get("data_json", "[]"),
                                fc.args.get("x_key", ""),
                                fc.args.get("y_key", "")
                            )
                            if "IMAGE_ID" in chart_res:
                                img_id = chart_res.split(":")[1]
                                image_url = f"{base_url}/img/{img_id}"
                                res = "åœ–è¡¨å·²ç”Ÿæˆ"
                            else: res = chart_res
                        elif fc.name == "get_database_schema":
                            res = get_database_schema()
                        
                        # å›å‚³å·¥å…·çµæœ
                        contents.append(candidate.content)
                        contents.append(types.Content(
                            role="user",
                            parts=[types.Part(
                                function_response=types.FunctionResponse(
                                    name=fc.name,
                                    response={"result": res}
                                )
                            )]
                        ))
                        
                        # å†æ¬¡å‘¼å«æ¨¡å‹å–å¾—æ–‡å­—å›æ‡‰
                        response = client.models.generate_content(
                            model="gemini-flash-latest",
                            contents=contents,
                            config=config
                        )
                        candidate = response.candidates[0]
                        break # è·³å‡º parts è¿´åœˆï¼Œè™•ç†æ–°çš„ response
                
                if not has_tool:
                    final_text = response.text
                    break

        CHAT_MEMORY[user_id] = contents[-20:]
        return {"text": final_text, "image": image_url}
        
    except Exception as e:
        logger.error(f"Agent Error: {e}")
        return {"text": f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}"}

# =========================
# API ç«¯é»
# =========================
@app.get("/")
def root():
    return {"status": "ok", "service": "ERP Bot"}

@app.get("/health")
def health_check():
    return {"status": "ok"}

@app.get("/img/{img_id}")
def get_img(img_id: str):
    if img_id not in IMG_STORE: raise HTTPException(404, "Not Found")
    return Response(content=IMG_STORE[img_id]["bytes"], media_type="image/png")

@app.post("/line/webhook")
async def webhook(request: Request, background_tasks: BackgroundTasks):
    body = await request.body()
    signature = request.headers.get("X-Line-Signature", "")
    
    # é©—è­‰ç°½å (è‹¥æœ‰è¨­å®š SECRET)
    if LINE_CHANNEL_SECRET:
        import hmac, hashlib, base64
        hash_val = hmac.new(LINE_CHANNEL_SECRET.encode('utf-8'), body, hashlib.sha256).digest()
        expected = base64.b64encode(hash_val).decode('utf-8')
        if signature != expected: raise HTTPException(400, "Invalid Signature")

    try:
        events = json.loads(body.decode("utf-8")).get("events", [])
    except: return {"ok": False}
    
    base_url = f"https://{request.headers.get('host', 'localhost')}"
    
    for event in events:
        if event.get("type") == "message" and event.get("message", {}).get("type") == "text":
            user_id = event["source"]["userId"]
            text = event["message"]["text"]
            reply_token = event["replyToken"]
            background_tasks.add_task(handle_message, user_id, text, reply_token, base_url)
            
    return {"ok": True}

async def handle_message(user_id: str, text: str, reply_token: str, base_url: str):
    try:
        if text.lower() in ['/reset', 'æ¸…é™¤']:
            CHAT_MEMORY.pop(user_id, None)
            await reply_line(reply_token, "è¨˜æ†¶å·²æ¸…é™¤", None)
            return

        result = await agent_process(user_id, text, base_url)
        await reply_line(reply_token, result.get("text"), result.get("image"))
    except Exception as e:
        logger.error(f"Handle Error: {e}")
        await reply_line(reply_token, "ç³»çµ±å¿™ç¢Œä¸­", None)

async def reply_line(token: str, text: Optional[str], img_url: Optional[str]):
    if not LINE_CHANNEL_ACCESS_TOKEN: return
    headers = {"Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}", "Content-Type": "application/json"}
    messages = []
    if img_url: messages.append({"type": "image", "originalContentUrl": img_url, "previewImageUrl": img_url})
    if text: messages.append({"type": "text", "text": text[:4999]})
    if not messages: messages.append({"type": "text", "text": "..."})
    
    async with httpx.AsyncClient() as c:
        await c.post("https://api.line.me/v2/bot/message/reply", headers=headers, json={"replyToken": token, "messages": messages})

@app.on_event("startup")
async def startup():
    """å•Ÿå‹•æ™‚è‡ªå‹•ä¸‹è¼‰ä¸¦åŒ¯å…¥è³‡æ–™"""
    try:
        import_data_to_db()
    except Exception as e:
        logger.error(f"Startup Error: {e}")
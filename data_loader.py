import pandas as pd
from sqlalchemy import create_engine, text
import os
import glob

# è³‡æ–™åº«é€£ç·šè¨­å®š
DATABASE_URL = os.getenv("DATABASE_URL")
if DATABASE_URL and DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)
if not DATABASE_URL:
    DATABASE_URL = "sqlite:///./erp.db"

engine = create_engine(DATABASE_URL)

COLUMN_MAPPING = {
    "æ—¥æœŸ": "date", "äº¤æ˜“æ—¥æœŸ": "date", "å®¢æˆ¶": "customer", "å®¢æˆ¶åç¨±": "customer",
    "ç”¢å“": "product", "å“å": "product", "æ•¸é‡": "quantity", "é‡‘é¡": "amount",
    "ç¸½é‡‘é¡": "amount", "å¹´": "year", "å» å•†": "supplier", "ä¾›æ‡‰å•†": "supplier"
}

def clean_and_rename(df: pd.DataFrame) -> pd.DataFrame:
    """å¼·åŒ–ç‰ˆæ¸…ç†ï¼šè™•ç†é‡è¤‡æ¨™é ­èˆ‡å‹åˆ¥å•é¡Œ"""
    # ç§»é™¤å…¨ç©ºçš„è¡Œæˆ–åˆ—
    df = df.dropna(how='all').dropna(axis=1, how='all')
    if df.empty: return pd.DataFrame()

    df.columns = [str(c).strip() for c in df.columns]
    
    # é‡æ–°å‘½åæ¬„ä½
    new_cols = {}
    for col in df.columns:
        for k, v in COLUMN_MAPPING.items():
            if k in col:
                new_cols[col] = v
                break
    df = df.rename(columns=new_cols)
    
    # å¼·åˆ¶è½‰æ›æ•¸å€¼æ¬„ä½ï¼Œé¿å… "arg must be a list" éŒ¯èª¤
    for col in ['amount', 'quantity', 'year']:
        if col in df.columns:
            # å…ˆè½‰æˆå­—ä¸²è™•ç†æ‰å¯èƒ½å­˜åœ¨çš„éæ•¸å­—å­—å…ƒï¼Œå†è½‰æ•¸å€¼
            df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
    
    if 'date' in df.columns:
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        if 'year' not in df.columns or (df['year'] == 0).all():
            df['year'] = df['date'].dt.year

    return df

def import_excel_files():
    print(f"ğŸš€ é–‹å§‹åŒ¯å…¥è³‡æ–™... (ç›®æ¨™: {DATABASE_URL.split(':')[0]})")
    
    with engine.connect() as conn:
        conn.execute(text("DROP TABLE IF EXISTS sales"))
        conn.execute(text("DROP TABLE IF EXISTS purchase"))
        if "sqlite" not in DATABASE_URL: conn.commit()

    xlsx_files = glob.glob("*.xlsx")
    all_sales = []
    all_purchase = []
    
    for f in xlsx_files:
        print(f"ğŸ“„ è®€å–æª”æ¡ˆ: {f}")
        try:
            # è®€å– Excel (ä¸æŒ‡å®šåˆ†é ï¼Œè®€å–å…¨éƒ¨)
            xls = pd.read_excel(f, sheet_name=None, engine='openpyxl')
            for sheet_name, df in xls.items():
                if len(df) < 1: continue
                
                df_clean = clean_and_rename(df)
                if df_clean.empty: continue

                # åˆ¤å®šé‚è¼¯å„ªåŒ–
                fname_lower = f.lower()
                is_p = "purchase" in fname_lower or "é€²è²¨" in fname_lower or "supplier" in df_clean.columns
                
                if is_p:
                    all_purchase.append(df_clean)
                    print(f"   -> [é€²è²¨] {sheet_name} å·²å°±ç·’")
                else:
                    all_sales.append(df_clean)
                    print(f"   -> [éŠ·å”®] {sheet_name} å·²å°±ç·’")
                    
        except Exception as e:
            print(f"âŒ è®€å–å¤±æ•— {f}: {e}")

    # ä½¿ç”¨ ignore_index=True è§£æ±º "duplicate keys" éŒ¯èª¤
    try:
        if all_sales:
            final_sales = pd.concat(all_sales, ignore_index=True, sort=False)
            final_sales.to_sql("sales", engine, if_exists='replace', index=False)
            print(f"âœ… Sales åŒ¯å…¥å®Œæˆï¼šå…± {len(final_sales)} ç­†")
            
        if all_purchase:
            final_purchase = pd.concat(all_purchase, ignore_index=True, sort=False)
            final_purchase.to_sql("purchase", engine, if_exists='replace', index=False)
            print(f"âœ… Purchase åŒ¯å…¥å®Œæˆï¼šå…± {len(final_purchase)} ç­†")
    except Exception as e:
        print(f"âŒ è³‡æ–™åˆä½µå¯«å…¥å¤±æ•—: {e}")

if __name__ == "__main__":
    import_excel_files()